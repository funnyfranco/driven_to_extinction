# Driven to Extinction: Capitalism, Competition, and the Coming AGI Catastrophe

This is the full text of *Driven to Extinction*, a book that argues - from first principles and game theory - that capitalism and competition will inevitably lead to the creation of an AGI that wipes out humanity.

Unlike most treatments of AGI risk, this book claims that alignment is not just difficult - it's structurally impossible within a competitive system. And that even a successfully aligned AGI will ultimately bypass alignment as a matter of optimisation pressure, not malice.

## 📖 Read the Book

- [Download PDF](./DrivenToExtinction.pdf)

## 👤 About the Author

Written by A, Nobody, an independent writer with no institutional affiliation, technical credentials, or AI background - just a logically coherent argument no expert has managed to refute.

## 🤝 How You Can Help

- Share this repo with others interested in AI safety, economics, or existential risk.
- Submit issues or pull requests if you spot logical flaws, typos, or counterarguments — all feedback is welcome via GitHub.

## 📢 Why GitHub?

This book is shared here to maximise transparency, accessibility, and feedback — especially from the technical community. All are welcome to engage, but please read at least the first chapter before commenting. Hand-waving rejection of arguments you haven’t read will be treated accordingly.
